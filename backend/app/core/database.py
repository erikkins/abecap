"""
Database configuration and connection
"""

import os
import uuid
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession, async_sessionmaker
from sqlalchemy.orm import DeclarativeBase
from sqlalchemy import Column, Integer, String, Float, DateTime, Boolean, ForeignKey, Text, JSON, Date, UniqueConstraint
from sqlalchemy.sql import func
from sqlalchemy.dialects.postgresql import UUID
from sqlalchemy.orm import relationship
from datetime import datetime, timedelta

from app.core.config import settings


# Convert sync URL to async
DATABASE_URL = settings.DATABASE_URL.replace("postgresql://", "postgresql+asyncpg://")

# Connection pool settings with timeout to fail fast if DB unavailable
engine = create_async_engine(
    DATABASE_URL,
    echo=settings.DEBUG,
    pool_pre_ping=True,
    pool_size=5,
    max_overflow=10,
    pool_timeout=3,  # 3 second timeout for getting connection from pool
    connect_args={
        "command_timeout": 5,  # 5 second query timeout
        "timeout": 3,  # 3 second connection timeout (asyncpg)
    }
)
async_session = async_sessionmaker(engine, class_=AsyncSession, expire_on_commit=False)


class Base(DeclarativeBase):
    pass


# Models
class StockData(Base):
    """Historical stock price data"""
    __tablename__ = "stock_data"
    
    id = Column(Integer, primary_key=True)
    symbol = Column(String(10), index=True, nullable=False)
    date = Column(DateTime, index=True, nullable=False)
    open = Column(Float)
    high = Column(Float)
    low = Column(Float)
    close = Column(Float, nullable=False)
    volume = Column(Float)
    dwap = Column(Float)
    ma_50 = Column(Float)
    ma_200 = Column(Float)
    created_at = Column(DateTime, default=datetime.utcnow)


class Signal(Base):
    """Trading signals generated by scanner"""
    __tablename__ = "signals"
    
    id = Column(Integer, primary_key=True)
    symbol = Column(String(10), index=True, nullable=False)
    signal_type = Column(String(10), nullable=False)  # BUY, SELL
    price = Column(Float, nullable=False)
    dwap = Column(Float)
    pct_above_dwap = Column(Float)
    volume = Column(Float)
    volume_ratio = Column(Float)
    stop_loss = Column(Float)
    profit_target = Column(Float)
    is_strong = Column(Boolean, default=False)
    created_at = Column(DateTime, default=datetime.utcnow, index=True)
    expires_at = Column(DateTime)
    status = Column(String(20), default="active")  # active, executed, expired


class PushToken(Base):
    """Expo push notification tokens for mobile app users"""
    __tablename__ = "push_tokens"

    id = Column(Integer, primary_key=True)
    user_id = Column(UUID(as_uuid=True), ForeignKey("users.id", ondelete="CASCADE"), nullable=False, index=True)
    token = Column(String(500), nullable=False, unique=True)
    platform = Column(String(20), nullable=False)  # "ios", "android"
    device_id = Column(String(255), nullable=True)
    is_active = Column(Boolean, default=True)
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, onupdate=datetime.utcnow)


class EnsembleSignal(Base):
    """Persisted ensemble buy signals for audit trail and email consistency"""
    __tablename__ = "ensemble_signals"

    id = Column(Integer, primary_key=True)
    signal_date = Column(Date, nullable=False, index=True)
    symbol = Column(String(10), nullable=False, index=True)
    price = Column(Float)
    dwap = Column(Float)
    pct_above_dwap = Column(Float)
    volume = Column(Float)
    volume_ratio = Column(Float)
    momentum_rank = Column(Integer)
    momentum_score = Column(Float)
    short_momentum = Column(Float)
    long_momentum = Column(Float)
    ensemble_score = Column(Float)
    dwap_crossover_date = Column(Date)
    ensemble_entry_date = Column(Date)
    days_since_crossover = Column(Integer)
    days_since_entry = Column(Integer)
    is_fresh = Column(Boolean, default=False)
    is_strong = Column(Boolean, default=False)
    sector = Column(String(50))
    status = Column(String(20), default="active", index=True)  # active, expired, invalidated
    invalidated_at = Column(DateTime, nullable=True)
    invalidation_reason = Column(String(100), nullable=True)
    created_at = Column(DateTime, default=datetime.utcnow)

    __table_args__ = (
        UniqueConstraint('signal_date', 'symbol', name='uq_ensemble_signal_date_symbol'),
    )


class Position(Base):
    """Open trading positions"""
    __tablename__ = "positions"

    id = Column(Integer, primary_key=True)
    user_id = Column(UUID(as_uuid=True), ForeignKey("users.id"), nullable=True, index=True)
    symbol = Column(String(10), index=True, nullable=False)
    entry_date = Column(DateTime, nullable=False)
    entry_price = Column(Float, nullable=False)
    shares = Column(Float, nullable=False)
    stop_loss = Column(Float)
    profit_target = Column(Float)
    highest_price = Column(Float)
    signal_id = Column(Integer, ForeignKey("signals.id"))
    status = Column(String(20), default="open")  # open, closed
    created_at = Column(DateTime, default=datetime.utcnow)
    
    trades = relationship("Trade", back_populates="position")


class Trade(Base):
    """Completed trades"""
    __tablename__ = "trades"

    id = Column(Integer, primary_key=True)
    user_id = Column(UUID(as_uuid=True), ForeignKey("users.id"), nullable=True, index=True)
    position_id = Column(Integer, ForeignKey("positions.id"))
    symbol = Column(String(10), index=True, nullable=False)
    entry_date = Column(DateTime, nullable=False)
    entry_price = Column(Float, nullable=False)
    exit_date = Column(DateTime, nullable=False)
    exit_price = Column(Float, nullable=False)
    shares = Column(Float, nullable=False)
    pnl = Column(Float)
    pnl_pct = Column(Float)
    exit_reason = Column(String(50))
    created_at = Column(DateTime, default=datetime.utcnow)
    
    position = relationship("Position", back_populates="trades")


class BacktestResult(Base):
    """Backtest run results"""
    __tablename__ = "backtest_results"

    id = Column(Integer, primary_key=True)
    name = Column(String(100))
    start_date = Column(DateTime)
    end_date = Column(DateTime)
    initial_capital = Column(Float)
    final_capital = Column(Float)
    total_return_pct = Column(Float)
    annual_return_pct = Column(Float)
    max_drawdown_pct = Column(Float)
    sharpe_ratio = Column(Float)
    win_rate = Column(Float)
    total_trades = Column(Integer)
    config = Column(Text)  # JSON string of config
    created_at = Column(DateTime, default=datetime.utcnow)


class StrategyDefinition(Base):
    """Trading strategy definitions"""
    __tablename__ = "strategy_definitions"

    id = Column(Integer, primary_key=True)
    name = Column(String(100), nullable=False, unique=True)
    description = Column(Text, nullable=True)
    strategy_type = Column(String(50), nullable=False)  # "dwap", "momentum"
    parameters = Column(Text, nullable=False)  # JSON string
    is_active = Column(Boolean, default=False, index=True)
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, onupdate=datetime.utcnow)
    activated_at = Column(DateTime, nullable=True)
    source = Column(String(50), default="manual")  # "manual", "ai_generated"
    is_custom = Column(Boolean, default=False)

    evaluations = relationship("StrategyEvaluation", back_populates="strategy")


class StrategyEvaluation(Base):
    """Strategy backtest evaluation results"""
    __tablename__ = "strategy_evaluations"

    id = Column(Integer, primary_key=True)
    strategy_id = Column(Integer, ForeignKey("strategy_definitions.id"))
    evaluation_date = Column(DateTime, default=datetime.utcnow)
    lookback_days = Column(Integer, default=90)  # 3-month rolling window

    # Performance metrics
    total_return_pct = Column(Float)
    sharpe_ratio = Column(Float)
    max_drawdown_pct = Column(Float)
    win_rate = Column(Float)
    total_trades = Column(Integer)

    # AI recommendation
    recommendation_score = Column(Float)  # 0-100
    recommendation_notes = Column(Text)

    strategy = relationship("StrategyDefinition", back_populates="evaluations")


class AutoSwitchConfig(Base):
    """Configuration for automated strategy switching"""
    __tablename__ = "auto_switch_config"

    id = Column(Integer, primary_key=True)
    is_enabled = Column(Boolean, default=False)
    analysis_frequency = Column(String(20), default="biweekly")  # weekly/biweekly/monthly
    min_score_diff_to_switch = Column(Float, default=10.0)
    min_days_since_last_switch = Column(Integer, default=14)
    notify_on_analysis = Column(Boolean, default=True)
    notify_on_switch = Column(Boolean, default=True)
    admin_email = Column(String(255))
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, onupdate=datetime.utcnow)


class StrategySwitchHistory(Base):
    """Audit log of all strategy switches"""
    __tablename__ = "strategy_switch_history"

    id = Column(Integer, primary_key=True)
    switch_date = Column(DateTime, default=datetime.utcnow, index=True)
    from_strategy_id = Column(Integer, ForeignKey("strategy_definitions.id"), nullable=True)
    to_strategy_id = Column(Integer, ForeignKey("strategy_definitions.id"), nullable=False)
    trigger = Column(String(50), nullable=False)  # "manual", "auto_scheduled"
    reason = Column(Text)
    score_before = Column(Float)
    score_after = Column(Float)

    from_strategy = relationship("StrategyDefinition", foreign_keys=[from_strategy_id])
    to_strategy = relationship("StrategyDefinition", foreign_keys=[to_strategy_id])


class WalkForwardSimulation(Base):
    """Walk-forward analysis simulation results"""
    __tablename__ = "walk_forward_simulations"

    id = Column(Integer, primary_key=True)
    simulation_date = Column(DateTime, default=datetime.utcnow, index=True)
    start_date = Column(DateTime, nullable=False)
    end_date = Column(DateTime, nullable=False)
    reoptimization_frequency = Column(String(20), nullable=False)  # weekly/biweekly/monthly
    total_return_pct = Column(Float)
    sharpe_ratio = Column(Float)
    max_drawdown_pct = Column(Float)
    num_strategy_switches = Column(Integer)
    benchmark_return_pct = Column(Float)
    switch_history_json = Column(Text)  # JSON array of switch events
    equity_curve_json = Column(Text)  # JSON array of equity points
    errors_json = Column(Text)  # JSON array of period debug info
    trades_json = Column(Text)  # JSON array of trades executed during simulation
    status = Column(String(20), default="completed")  # pending/completed/failed
    is_daily_cache = Column(Boolean, default=False, index=True)  # For dashboard cached results
    step_functions_arn = Column(String(500), nullable=True)  # Step Functions execution ARN
    is_nightly_missed_opps = Column(Boolean, default=False, index=True)  # For nightly missed opportunities cache

    period_results = relationship("WalkForwardPeriodResult", back_populates="simulation", cascade="all, delete-orphan")


class WalkForwardPeriodResult(Base):
    """Per-period results for Step Functions walk-forward simulation.

    Stores period data in DB instead of accumulating in Step Functions state
    (which has a 256KB limit). Cleaned up after finalization.
    """
    __tablename__ = "walk_forward_period_results"

    id = Column(Integer, primary_key=True)
    simulation_id = Column(Integer, ForeignKey("walk_forward_simulations.id"), index=True, nullable=False)
    period_index = Column(Integer, nullable=False)
    period_start = Column(DateTime)
    period_end = Column(DateTime)
    starting_capital = Column(Float)
    ending_capital = Column(Float)
    period_return_pct = Column(Float)
    strategy_name = Column(String(100))
    strategy_type = Column(String(50))
    is_ai_params = Column(Boolean, default=False)
    switch_event_json = Column(Text)       # SwitchEvent dict or null
    trades_json = Column(Text)             # Array of PeriodTrade dicts
    equity_points_json = Column(Text)      # Equity curve points for this period
    ai_optimization_json = Column(Text)    # AIOptimizationResult dict or null
    parameter_snapshot_json = Column(Text)  # ParameterSnapshot dict or null
    error_info = Column(Text)

    simulation = relationship("WalkForwardSimulation", back_populates="period_results")


class StrategyGenerationRun(Base):
    """Track AI-generated strategy optimization runs"""
    __tablename__ = "strategy_generation_runs"

    id = Column(Integer, primary_key=True)
    run_date = Column(DateTime, default=datetime.utcnow, index=True)
    lookback_weeks = Column(Integer, nullable=False)
    strategy_type = Column(String(50), nullable=False)
    optimization_metric = Column(String(50), nullable=False)  # sharpe/return/calmar
    market_regime_detected = Column(String(50))  # bull/bear/neutral
    best_params_json = Column(Text)  # JSON of best parameters found
    expected_sharpe = Column(Float)
    expected_return_pct = Column(Float)
    expected_drawdown_pct = Column(Float)
    combinations_tested = Column(Integer)
    status = Column(String(20), default="pending")  # pending/completed/failed
    created_strategy_id = Column(Integer, ForeignKey("strategy_definitions.id"), nullable=True)

    created_strategy = relationship("StrategyDefinition")


class SocialPost(Base):
    """Social media post queue for admin review/approval"""
    __tablename__ = "social_posts"

    id = Column(Integer, primary_key=True)
    post_type = Column(String(50))  # trade_result, missed_opportunity, weekly_recap, regime_commentary
    platform = Column(String(20))  # twitter, instagram
    status = Column(String(20), default="draft")  # draft, approved, rejected, posted, cancelled, scheduled, publish_failed
    text_content = Column(Text)
    hashtags = Column(Text, nullable=True)
    image_s3_key = Column(String(500), nullable=True)
    image_metadata_json = Column(Text, nullable=True)
    source_simulation_id = Column(Integer, nullable=True)
    source_trade_json = Column(Text, nullable=True)
    source_data_json = Column(Text, nullable=True)
    scheduled_for = Column(DateTime, nullable=True)
    posted_at = Column(DateTime, nullable=True)
    reviewed_by = Column(String(100), nullable=True)
    reviewed_at = Column(DateTime, nullable=True)
    rejection_reason = Column(Text, nullable=True)
    # AI content generation metadata
    ai_generated = Column(Boolean, default=False)
    ai_model = Column(String(50), nullable=True)
    ai_prompt_hash = Column(String(64), nullable=True)
    news_context_json = Column(Text, nullable=True)
    # Admin notification tracking
    notification_24h_sent = Column(Boolean, default=False)
    notification_1h_sent = Column(Boolean, default=False)
    # Reply-specific columns (contextual_reply post type)
    reply_to_tweet_id = Column(String(50), nullable=True)
    reply_to_username = Column(String(50), nullable=True)
    source_tweet_text = Column(Text, nullable=True)
    # Threads reply column
    reply_to_thread_id = Column(String(50), nullable=True)
    # Instagram comment reply columns
    reply_to_instagram_comment_id = Column(String(50), nullable=True)
    reply_to_instagram_media_id = Column(String(50), nullable=True)
    publish_attempts = Column(Integer, default=0)
    created_at = Column(DateTime, default=func.now())
    updated_at = Column(DateTime, default=func.now(), onupdate=func.now())


class ModelPosition(Base):
    """Model portfolio positions (live or walk-forward tracking)"""
    __tablename__ = "model_positions"

    id = Column(Integer, primary_key=True)
    portfolio_type = Column(String(20), nullable=False, index=True)  # "live" or "walkforward"
    symbol = Column(String(10), nullable=False, index=True)
    entry_date = Column(DateTime, nullable=False)
    entry_price = Column(Float, nullable=False)
    shares = Column(Float, nullable=False)
    cost_basis = Column(Float, nullable=False)
    highest_price = Column(Float)
    exit_date = Column(DateTime, nullable=True)
    exit_price = Column(Float, nullable=True)
    exit_reason = Column(String(50), nullable=True)
    pnl_dollars = Column(Float, nullable=True)
    pnl_pct = Column(Float, nullable=True)
    signal_data_json = Column(Text, nullable=True)
    status = Column(String(20), default="open", index=True)
    social_post_generated = Column(Boolean, default=False)
    autopsy_json = Column(Text, nullable=True)
    created_at = Column(DateTime, default=datetime.utcnow)


class ModelPortfolioSnapshot(Base):
    """Daily equity curve snapshots for model portfolios"""
    __tablename__ = "model_portfolio_snapshots"

    id = Column(Integer, primary_key=True)
    portfolio_type = Column(String(20), nullable=False, index=True)
    snapshot_date = Column(DateTime, nullable=False, index=True)
    total_value = Column(Float, nullable=False)
    cash = Column(Float, nullable=False)
    positions_value = Column(Float, nullable=False)
    num_positions = Column(Integer, nullable=False, default=0)
    spy_close = Column(Float, nullable=True)
    created_at = Column(DateTime, default=datetime.utcnow)


class ModelPortfolioState(Base):
    """Aggregate state for each model portfolio"""
    __tablename__ = "model_portfolio_state"

    id = Column(Integer, primary_key=True)
    portfolio_type = Column(String(20), nullable=False, unique=True)
    starting_capital = Column(Float, default=100000.0)
    current_cash = Column(Float, default=100000.0)
    total_trades = Column(Integer, default=0)
    winning_trades = Column(Integer, default=0)
    total_pnl = Column(Float, default=0.0)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)


class RegimeForecastSnapshot(Base):
    """Daily regime forecast snapshots for historical tracking"""
    __tablename__ = "regime_forecast_snapshots"

    id = Column(Integer, primary_key=True)
    snapshot_date = Column(DateTime, nullable=False, unique=True, index=True)
    current_regime = Column(String(30), nullable=False)
    probabilities_json = Column(Text, nullable=False)
    outlook = Column(String(20))
    recommended_action = Column(String(30))
    risk_change = Column(String(20))
    spy_close = Column(Float)
    vix_close = Column(Float)
    created_at = Column(DateTime, default=datetime.utcnow)


class EmailSubscriber(Base):
    """Lightweight email subscribers (no account required)"""
    __tablename__ = "email_subscribers"

    id = Column(Integer, primary_key=True)
    email = Column(String(255), unique=True, nullable=False, index=True)
    source = Column(String(50), default="regime_report")
    is_active = Column(Boolean, default=True)
    created_at = Column(DateTime, default=datetime.utcnow)
    unsubscribed_at = Column(DateTime, nullable=True)


class User(Base):
    """User account for authentication and subscription management"""
    __tablename__ = "users"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    email = Column(String(255), unique=True, nullable=False, index=True)
    password_hash = Column(String(255), nullable=True)  # Null for OAuth users
    name = Column(String(255), nullable=True)
    role = Column(String(20), default="user")  # "admin" or "user"
    is_active = Column(Boolean, default=True)

    # OAuth identifiers
    google_id = Column(String(255), nullable=True, unique=True)
    apple_id = Column(String(255), nullable=True, unique=True)

    # Stripe customer ID
    stripe_customer_id = Column(String(255), nullable=True, unique=True)

    # Email preferences: {"daily_digest": true, "sell_alerts": true, ...}
    email_preferences = Column(JSON, nullable=True)

    # Onboarding drip sequence: 0=none sent, 1-5=last step sent
    onboarding_step = Column(Integer, default=0)

    # TOTP 2FA
    totp_secret = Column(String(64), nullable=True)
    totp_enabled = Column(Boolean, default=False)
    totp_backup_codes = Column(Text, nullable=True)      # JSON array of bcrypt hashes
    totp_trusted_devices = Column(Text, nullable=True)    # JSON array of {device_id, expires_at}

    # Referral program
    referral_code = Column(String(12), unique=True, nullable=True, index=True)
    referred_by = Column(UUID(as_uuid=True), ForeignKey("users.id"), nullable=True)
    referral_count = Column(Integer, default=0)

    # Timestamps
    created_at = Column(DateTime, default=datetime.utcnow)
    last_login = Column(DateTime, nullable=True)

    # Relationships
    subscription = relationship("Subscription", back_populates="user", uselist=False)

    def is_admin(self) -> bool:
        """Check if user has admin privileges via email allowlist."""
        admin_emails = set(
            e.strip().lower()
            for e in os.environ.get('ADMIN_EMAILS', 'erik@rigacap.com').split(',')
            if e.strip()
        )
        return (self.email or '').lower() in admin_emails

    def get_email_preference(self, pref_key: str) -> bool:
        """Returns True unless explicitly set to False."""
        if not self.email_preferences:
            return True
        return self.email_preferences.get(pref_key, True)

    def to_dict(self, include_subscription: bool = False) -> dict:
        """Convert user to dictionary for API responses.

        Note: Don't access self.subscription here as it triggers lazy loading
        which doesn't work with async SQLAlchemy. The subscription is loaded
        separately in the auth endpoints and added to the response.
        """
        defaults = {"daily_digest": True, "sell_alerts": True, "double_signals": True, "intraday_signals": True, "regime_report": True}
        prefs = {**defaults, **(self.email_preferences or {})}
        result = {
            "id": str(self.id),
            "email": self.email,
            "name": self.name,
            "role": self.role,
            "is_active": self.is_active,
            "created_at": self.created_at.isoformat() if self.created_at else None,
            "last_login": self.last_login.isoformat() if self.last_login else None,
            "email_preferences": prefs,
            "referral_code": self.referral_code,
            "referral_count": self.referral_count or 0,
            "totp_enabled": bool(self.totp_enabled),
        }
        return result


class Subscription(Base):
    """User subscription for trial and payment management"""
    __tablename__ = "subscriptions"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    user_id = Column(UUID(as_uuid=True), ForeignKey("users.id"), nullable=False, unique=True)

    # Status: trial, active, canceled, expired, past_due
    status = Column(String(20), default="trial")

    # Trial tracking (no card required)
    trial_start = Column(DateTime, default=datetime.utcnow)
    trial_end = Column(DateTime)

    # Stripe subscription (after trial converts)
    stripe_subscription_id = Column(String(255), nullable=True)
    stripe_price_id = Column(String(255), nullable=True)

    # Billing periods
    current_period_start = Column(DateTime, nullable=True)
    current_period_end = Column(DateTime, nullable=True)
    cancel_at_period_end = Column(Boolean, default=False)

    # Timestamps
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, onupdate=datetime.utcnow)

    # Relationships
    user = relationship("User", back_populates="subscription")

    @classmethod
    def create_trial(cls, user_id) -> "Subscription":
        """Create a new trial subscription."""
        now = datetime.utcnow()
        return cls(
            user_id=user_id,
            status="trial",
            trial_start=now,
            trial_end=now + timedelta(days=7),
        )

    def is_valid(self) -> bool:
        """Check if subscription is currently valid (trial or active)."""
        now = datetime.utcnow()

        if self.status == "trial":
            return self.trial_end and now < self.trial_end

        if self.status == "active":
            if self.current_period_end:
                return now < self.current_period_end
            return True

        return False

    def days_remaining(self) -> int:
        """Get days remaining in trial or current period."""
        now = datetime.utcnow()

        if self.status == "trial" and self.trial_end:
            delta = self.trial_end - now
            return max(0, delta.days)

        if self.status == "active" and self.current_period_end:
            delta = self.current_period_end - now
            return max(0, delta.days)

        return 0

    def to_dict(self) -> dict:
        """Convert subscription to dictionary for API responses."""
        return {
            "id": str(self.id),
            "status": self.status,
            "is_valid": self.is_valid(),
            "days_remaining": self.days_remaining(),
            "trial_start": self.trial_start.isoformat() if self.trial_start else None,
            "trial_end": self.trial_end.isoformat() if self.trial_end else None,
            "current_period_start": self.current_period_start.isoformat() if self.current_period_start else None,
            "current_period_end": self.current_period_end.isoformat() if self.current_period_end else None,
            "cancel_at_period_end": self.cancel_at_period_end,
            "has_stripe_subscription": bool(self.stripe_subscription_id),
        }


# Track database availability (set during init_db)
db_available = False
db_init_attempted = False


async def _run_schema_migrations(conn):
    """Run schema migrations for columns that don't exist yet.

    Each migration runs in a SAVEPOINT so a single failure doesn't
    invalidate the outer transaction and cascade-fail all remaining
    migrations.
    """
    from sqlalchemy import text

    async def _run(label: str, statements):
        """Run one or more SQL statements inside a savepoint."""
        try:
            async with conn.begin_nested():
                if isinstance(statements, str):
                    statements = [statements]
                for sql in statements:
                    await conn.execute(text(sql))
            print(f"✅ Schema migration: {label}")
        except Exception as e:
            print(f"⚠️ Schema migration skipped ({label}): {e}")
            try:
                await conn.rollback()
            except Exception:
                pass

    await _run("is_daily_cache column", """
        ALTER TABLE walk_forward_simulations
        ADD COLUMN IF NOT EXISTS is_daily_cache BOOLEAN DEFAULT FALSE
    """)

    await _run("errors_json column", """
        ALTER TABLE walk_forward_simulations
        ADD COLUMN IF NOT EXISTS errors_json TEXT
    """)

    await _run("trades_json column", """
        ALTER TABLE walk_forward_simulations
        ADD COLUMN IF NOT EXISTS trades_json TEXT
    """)

    await _run("step_functions_arn column", """
        ALTER TABLE walk_forward_simulations
        ADD COLUMN IF NOT EXISTS step_functions_arn VARCHAR(500)
    """)

    await _run("is_nightly_missed_opps column", """
        ALTER TABLE walk_forward_simulations
        ADD COLUMN IF NOT EXISTS is_nightly_missed_opps BOOLEAN DEFAULT FALSE
    """)

    await _run("social_posts table", """
        CREATE TABLE IF NOT EXISTS social_posts (
            id SERIAL PRIMARY KEY,
            post_type VARCHAR(50),
            platform VARCHAR(20),
            status VARCHAR(20) DEFAULT 'draft',
            text_content TEXT,
            hashtags TEXT,
            image_s3_key VARCHAR(500),
            image_metadata_json TEXT,
            source_simulation_id INTEGER,
            source_trade_json TEXT,
            source_data_json TEXT,
            scheduled_for TIMESTAMP,
            posted_at TIMESTAMP,
            reviewed_by VARCHAR(100),
            reviewed_at TIMESTAMP,
            rejection_reason TEXT,
            created_at TIMESTAMP DEFAULT NOW(),
            updated_at TIMESTAMP DEFAULT NOW()
        )
    """)

    await _run("social_posts AI/scheduling columns", [
        "ALTER TABLE social_posts ADD COLUMN IF NOT EXISTS ai_generated BOOLEAN DEFAULT FALSE",
        "ALTER TABLE social_posts ADD COLUMN IF NOT EXISTS ai_model VARCHAR(50)",
        "ALTER TABLE social_posts ADD COLUMN IF NOT EXISTS ai_prompt_hash VARCHAR(64)",
        "ALTER TABLE social_posts ADD COLUMN IF NOT EXISTS news_context_json TEXT",
        "ALTER TABLE social_posts ADD COLUMN IF NOT EXISTS notification_24h_sent BOOLEAN DEFAULT FALSE",
        "ALTER TABLE social_posts ADD COLUMN IF NOT EXISTS notification_1h_sent BOOLEAN DEFAULT FALSE",
    ])

    await _run("social_posts reply columns", [
        "ALTER TABLE social_posts ADD COLUMN IF NOT EXISTS reply_to_tweet_id VARCHAR(50)",
        "ALTER TABLE social_posts ADD COLUMN IF NOT EXISTS reply_to_username VARCHAR(50)",
        "ALTER TABLE social_posts ADD COLUMN IF NOT EXISTS source_tweet_text TEXT",
    ])

    await _run("social_posts threads + instagram comment columns", [
        "ALTER TABLE social_posts ADD COLUMN IF NOT EXISTS reply_to_thread_id VARCHAR(50)",
        "ALTER TABLE social_posts ADD COLUMN IF NOT EXISTS reply_to_instagram_comment_id VARCHAR(50)",
        "ALTER TABLE social_posts ADD COLUMN IF NOT EXISTS reply_to_instagram_media_id VARCHAR(50)",
    ])

    await _run("social_posts publish retry tracking", [
        "ALTER TABLE social_posts ADD COLUMN IF NOT EXISTS publish_attempts INTEGER DEFAULT 0",
    ])

    await _run("walk_forward_period_results table", [
        """CREATE TABLE IF NOT EXISTS walk_forward_period_results (
            id SERIAL PRIMARY KEY,
            simulation_id INTEGER NOT NULL REFERENCES walk_forward_simulations(id),
            period_index INTEGER NOT NULL,
            period_start TIMESTAMP,
            period_end TIMESTAMP,
            starting_capital FLOAT,
            ending_capital FLOAT,
            period_return_pct FLOAT,
            strategy_name VARCHAR(100),
            strategy_type VARCHAR(50),
            is_ai_params BOOLEAN DEFAULT FALSE,
            switch_event_json TEXT,
            trades_json TEXT,
            equity_points_json TEXT,
            ai_optimization_json TEXT,
            parameter_snapshot_json TEXT,
            error_info TEXT
        )""",
        """CREATE INDEX IF NOT EXISTS idx_wfpr_simulation_id
           ON walk_forward_period_results(simulation_id)""",
    ])

    await _run("email_preferences column", """
        ALTER TABLE users ADD COLUMN IF NOT EXISTS email_preferences JSON
    """)

    await _run("onboarding_step column", [
        "ALTER TABLE users ADD COLUMN IF NOT EXISTS onboarding_step INTEGER DEFAULT 0",
        "UPDATE users SET onboarding_step = 5 WHERE onboarding_step = 0 AND created_at < NOW() - INTERVAL '1 day'",
    ])

    await _run("referral program columns", [
        "ALTER TABLE users ADD COLUMN IF NOT EXISTS referral_code VARCHAR(12)",
        "ALTER TABLE users ADD COLUMN IF NOT EXISTS referred_by UUID REFERENCES users(id)",
        "ALTER TABLE users ADD COLUMN IF NOT EXISTS referral_count INTEGER DEFAULT 0",
        "CREATE UNIQUE INDEX IF NOT EXISTS idx_users_referral_code ON users(referral_code)",
        """UPDATE users SET referral_code = UPPER(SUBSTRING(MD5(id::text || created_at::text) FROM 1 FOR 8))
           WHERE referral_code IS NULL""",
    ])

    await _run("user_id columns on positions/trades", [
        "ALTER TABLE positions ADD COLUMN IF NOT EXISTS user_id UUID REFERENCES users(id)",
        "CREATE INDEX IF NOT EXISTS idx_positions_user_id ON positions(user_id)",
        "ALTER TABLE trades ADD COLUMN IF NOT EXISTS user_id UUID REFERENCES users(id)",
        "CREATE INDEX IF NOT EXISTS idx_trades_user_id ON trades(user_id)",
        "UPDATE positions SET user_id = (SELECT id FROM users WHERE email = 'erik@rigacap.com') WHERE user_id IS NULL",
        "UPDATE trades SET user_id = (SELECT id FROM users WHERE email = 'erik@rigacap.com') WHERE user_id IS NULL",
    ])

    await _run("model_positions table", [
        """CREATE TABLE IF NOT EXISTS model_positions (
            id SERIAL PRIMARY KEY,
            portfolio_type VARCHAR(20) NOT NULL,
            symbol VARCHAR(10) NOT NULL,
            entry_date TIMESTAMP NOT NULL,
            entry_price FLOAT NOT NULL,
            shares FLOAT NOT NULL,
            cost_basis FLOAT NOT NULL,
            highest_price FLOAT,
            exit_date TIMESTAMP,
            exit_price FLOAT,
            exit_reason VARCHAR(50),
            pnl_dollars FLOAT,
            pnl_pct FLOAT,
            signal_data_json TEXT,
            status VARCHAR(20) DEFAULT 'open',
            social_post_generated BOOLEAN DEFAULT FALSE,
            created_at TIMESTAMP DEFAULT NOW()
        )""",
        "CREATE INDEX IF NOT EXISTS idx_mp_status ON model_positions(status)",
        "CREATE INDEX IF NOT EXISTS idx_mp_portfolio ON model_positions(portfolio_type)",
        "CREATE INDEX IF NOT EXISTS idx_mp_symbol ON model_positions(symbol)",
    ])

    await _run("model_portfolio_snapshots table", [
        """CREATE TABLE IF NOT EXISTS model_portfolio_snapshots (
            id SERIAL PRIMARY KEY,
            portfolio_type VARCHAR(20) NOT NULL,
            snapshot_date TIMESTAMP NOT NULL,
            total_value FLOAT NOT NULL,
            cash FLOAT NOT NULL,
            positions_value FLOAT NOT NULL,
            num_positions INTEGER NOT NULL DEFAULT 0,
            spy_close FLOAT,
            created_at TIMESTAMP DEFAULT NOW()
        )""",
        "CREATE INDEX IF NOT EXISTS idx_mps_portfolio ON model_portfolio_snapshots(portfolio_type)",
        "CREATE INDEX IF NOT EXISTS idx_mps_date ON model_portfolio_snapshots(snapshot_date)",
        "CREATE UNIQUE INDEX IF NOT EXISTS idx_mps_type_date ON model_portfolio_snapshots(portfolio_type, snapshot_date)",
    ])

    await _run("model_portfolio_state table", """
        CREATE TABLE IF NOT EXISTS model_portfolio_state (
            id SERIAL PRIMARY KEY,
            portfolio_type VARCHAR(20) NOT NULL UNIQUE,
            starting_capital FLOAT DEFAULT 100000.0,
            current_cash FLOAT DEFAULT 100000.0,
            total_trades INTEGER DEFAULT 0,
            winning_trades INTEGER DEFAULT 0,
            total_pnl FLOAT DEFAULT 0.0,
            updated_at TIMESTAMP DEFAULT NOW()
        )
    """)

    await _run("autopsy_json column on model_positions", """
        ALTER TABLE model_positions ADD COLUMN IF NOT EXISTS autopsy_json TEXT
    """)

    await _run("regime_forecast_snapshots table", [
        """CREATE TABLE IF NOT EXISTS regime_forecast_snapshots (
            id SERIAL PRIMARY KEY,
            snapshot_date TIMESTAMP NOT NULL UNIQUE,
            current_regime VARCHAR(30) NOT NULL,
            probabilities_json TEXT NOT NULL,
            outlook VARCHAR(20),
            recommended_action VARCHAR(30),
            risk_change VARCHAR(20),
            spy_close FLOAT,
            vix_close FLOAT,
            created_at TIMESTAMP DEFAULT NOW()
        )""",
        "CREATE INDEX IF NOT EXISTS idx_rfs_date ON regime_forecast_snapshots(snapshot_date)",
    ])

    await _run("push_tokens table", [
        """CREATE TABLE IF NOT EXISTS push_tokens (
            id SERIAL PRIMARY KEY,
            user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
            token VARCHAR(500) NOT NULL UNIQUE,
            platform VARCHAR(20) NOT NULL,
            device_id VARCHAR(255),
            is_active BOOLEAN DEFAULT TRUE,
            created_at TIMESTAMP DEFAULT NOW(),
            updated_at TIMESTAMP
        )""",
        "CREATE INDEX IF NOT EXISTS idx_push_tokens_user_id ON push_tokens(user_id)",
    ])

    await _run("TOTP 2FA columns on users", [
        "ALTER TABLE users ADD COLUMN IF NOT EXISTS totp_secret VARCHAR(64)",
        "ALTER TABLE users ADD COLUMN IF NOT EXISTS totp_enabled BOOLEAN DEFAULT FALSE",
        "ALTER TABLE users ADD COLUMN IF NOT EXISTS totp_backup_codes TEXT",
        "ALTER TABLE users ADD COLUMN IF NOT EXISTS totp_trusted_devices TEXT",
    ])

    await _run("email_subscribers table", [
        """CREATE TABLE IF NOT EXISTS email_subscribers (
            id SERIAL PRIMARY KEY,
            email VARCHAR(255) UNIQUE NOT NULL,
            source VARCHAR(50) DEFAULT 'regime_report',
            is_active BOOLEAN DEFAULT TRUE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            unsubscribed_at TIMESTAMP
        )""",
        "CREATE INDEX IF NOT EXISTS idx_email_subscribers_email ON email_subscribers(email)",
    ])

    await _run("ensemble_signals table", [
        """CREATE TABLE IF NOT EXISTS ensemble_signals (
            id SERIAL PRIMARY KEY,
            signal_date DATE NOT NULL,
            symbol VARCHAR(10) NOT NULL,
            price FLOAT,
            dwap FLOAT,
            pct_above_dwap FLOAT,
            volume FLOAT,
            volume_ratio FLOAT,
            momentum_rank INTEGER,
            momentum_score FLOAT,
            short_momentum FLOAT,
            long_momentum FLOAT,
            ensemble_score FLOAT,
            dwap_crossover_date DATE,
            ensemble_entry_date DATE,
            days_since_crossover INTEGER,
            days_since_entry INTEGER,
            is_fresh BOOLEAN DEFAULT FALSE,
            is_strong BOOLEAN DEFAULT FALSE,
            sector VARCHAR(50),
            status VARCHAR(20) DEFAULT 'active',
            invalidated_at TIMESTAMP,
            invalidation_reason VARCHAR(100),
            created_at TIMESTAMP DEFAULT NOW(),
            UNIQUE(signal_date, symbol)
        )""",
        "CREATE INDEX IF NOT EXISTS idx_es_signal_date ON ensemble_signals(signal_date)",
        "CREATE INDEX IF NOT EXISTS idx_es_symbol ON ensemble_signals(symbol)",
        "CREATE INDEX IF NOT EXISTS idx_es_status ON ensemble_signals(status)",
    ])


async def init_db():
    """Initialize database tables"""
    global db_available, db_init_attempted
    db_init_attempted = True

    try:
        async with engine.begin() as conn:
            await conn.run_sync(Base.metadata.create_all)
            # Run any pending schema migrations
            await _run_schema_migrations(conn)
        db_available = True
        print("✅ Database initialized")
    except Exception as e:
        print(f"⚠️ Database init failed: {e}")
        db_available = False
        raise


async def get_db():
    """Dependency for getting database session - with lazy initialization"""
    from fastapi import HTTPException, status
    global db_available, db_init_attempted

    # Lazy initialization: try to init DB on first request, or retry if previous attempt failed
    if not db_available:
        try:
            await init_db()
        except Exception as e:
            print(f"⚠️ Lazy DB init failed: {e}")

    if not db_available:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Database not available. Running in memory-only mode."
        )

    async with async_session() as session:
        yield session
